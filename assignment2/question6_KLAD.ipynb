{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Just for in this notebook\n",
    "import sys\n",
    "sys.path.append('../assignment1/to_hand_in/')\n",
    "\n",
    "import some_routines as sr\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Classifying $\\gamma$-ray bursts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRBs are classified as short or long based on their time scale. Here we classify a GRB as long if $T_{90}$ (the time within which the detector receives 90% of the $\\gamma$-rays) is above 10 seconds and short otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values that are -1.0 correspond to non-determined variables. Use logistic regression to make a model of the data, using binary classification for short (0) or long (1). Feel free to break the data up into a training, validation and test set, but it's not required. \n",
    "\n",
    "#### Explain which properties your model uses to predict whether a GRB is short or long, and how you handle missing data. Plot a hisotgram of the class 0,1 of the GRB and overplot the actual class based on the value of T90. Can choose hyperparameters manually. Don't overfit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is similar to linear regression, where we fit a model $$\\hat{y} = h_\\theta(\\vec{x}) = \\vec{\\theta}^T \\vec{x} + b$$ with parameters $\\vec{\\theta}$ and $b$ to features $\\vec{x}$. The difference with linear regression is that we now use the sigmoid function as activation function, to limit the output between 0 and 1. The sigmoid function is defined as\n",
    "\\begin{equation}\n",
    "\\sigma(y) = \\frac{1}{1+e^{-y}}\n",
    "\\end{equation}\n",
    "It has the nice property that \n",
    "\\begin{equation}\\label{eq:derivsigm}\n",
    "\\frac{\\partial }{\\partial y} \\sigma(y) = \\sigma(y)(1-\\sigma(y)),\n",
    "\\end{equation}\n",
    "which allows us to calculate the derivative with already known values.\n",
    "Thus the prediction function for logistic regression is\n",
    "\\begin{equation}\n",
    "\\hat{y} = h_\\theta(\\vec{x}) = \\sigma( \\vec{\\theta}^T \\vec{x} + b)\n",
    "\\end{equation}\n",
    "\n",
    "We optimize the prediction function by minimizing the loss function. The loss function is defined as the binary cross-entropy loss function:\n",
    "\\begin{equation}\n",
    "J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} y_i \\log(h_\\theta(\\vec{x}_i)) + (1-y_i) \\log(1-h_\\theta(\\vec{x}_i))\n",
    "\\end{equation}\n",
    "where $m$ is the number of training examples.\n",
    "\n",
    "The loss function shall be minimized using gradient descent:\n",
    "\\begin{equation}\n",
    "\\theta_j = \\theta_j - \\alpha \\frac{\\partial J(\\theta) }{\\partial \\theta_j}\n",
    "\\end{equation}\n",
    "where $\\alpha$ a hyperparameter called the learning rate. \n",
    "Using the property of the sigmoid function (Eq. \\ref{eq:derivsigm}), the derivative of the loss function with respect to the parameters $\\theta$ is then by\n",
    "\\begin{equation}\n",
    "\\frac{\\partial J(\\theta) }{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(\\vec{x_i}) - y_i) x_{i,j}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "where $x_{i,j}$ denotes the $j$-th feature of example $i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, we can vectorize all computations except the iterations of gradient descent by using matrices and dot products. We initialize $\\theta$ as an ($n\\times 1$) array and $X$ as an ($m\\times$n) array. Because of \\textit{Numpy} broadcasting $b$ can just be a float. The prediction of all training examples is then given by a dot product\n",
    "\\begin{equation}\n",
    "\\hat{y} = \\sigma(X\\cdot\\theta + b)\n",
    "\\end{equation}\n",
    "In this way, $\\hat{y}$ is an $m\\times 1$ array containing the predictions of all the training examples.\n",
    "\n",
    "The backpropagation can also be vectorized, since we can calculate the derivatives as follows\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum (\\hat{y} - y) \\\\\n",
    "\\frac{\\partial J}{\\partial \\theta} = \\frac{1}{m} X^T \\cdot (\\hat{y}-y)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "where $y$ is now the ($m\\times 1$) array containing the true labels. In this setup $\\frac{\\partial J}{\\partial \\theta}$ is an $n\\times 1$ array containing the derivatives with respect to the $\\theta$ array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to standardize all features to have 0 mean and unit variance. For this standardization, we ignore the missing values. After standardization, we make sure that all missing values are set to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    \"\"\"\n",
    "    Calculate the sigmoid function for vector X\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bincrossent(y, yhat):\n",
    "    \"\"\"\n",
    "    Given yhat and y\n",
    "    Calculate the binary cross entropy\n",
    "    \"\"\"\n",
    "    m = np.shape(yhat)[0]\n",
    "        \n",
    "    return -1/m *( np.dot(y.T,np.log(yhat)) + np.dot(\n",
    "                                        (1-y).T,np.log(1-yhat)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(w, X, b, y, alpha, calcLoss=False):\n",
    "    \"\"\"\n",
    "    Perform one iteration of gradient descent.\n",
    "    n is amount of features.\n",
    "    m is amount of examples.\n",
    "    \n",
    "    w     -- (nx1) array -- weights  (also called parameters theta)\n",
    "    X     -- (mxn) array -- features \n",
    "    b     -- float       -- bias   \n",
    "    y     -- (mx1) array -- true labels \n",
    "    alpha -- float       -- learning rate\n",
    "    calcLoss -- bool -- whether to calculate and return the loss value\n",
    "    \n",
    "    Returns \n",
    "    w -- updated weights\n",
    "    b -- updated biases\n",
    "    \n",
    "    \"\"\"\n",
    "    m = np.shape(X)[0]\n",
    "    invm = 1/m\n",
    "    \n",
    "    # prediction\n",
    "    yhat = sigmoid(np.dot(X,w)+b)\n",
    "    # error\n",
    "    err = yhat - y\n",
    "    # derivative w.r.t the weights\n",
    "    dw = invm * np.dot(X.T,err)\n",
    "    # derivative w.r.t. the bias\n",
    "    db = invm * np.sum(err)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    w -= alpha*dw\n",
    "    b -= alpha*db\n",
    "    \n",
    "    if calcLoss:\n",
    "        # calculate loss before the update\n",
    "        loss = bincrossent(y,yhat)\n",
    "        return w, b, loss\n",
    "    else:        \n",
    "        return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(T90):\n",
    "    \"\"\"\n",
    "    Reads in the T90 values and assigns a label based on T90\n",
    "    short (0) if T90 <= 10\n",
    "    long  (1) if T90 > 10\n",
    "    \"\"\"\n",
    "    labels = np.array(T90>10,dtype='float')[:,np.newaxis] # return the necessary shape\n",
    "    return labels\n",
    "\n",
    "def standardize(features, setmean=False):\n",
    "    \"\"\"\n",
    "    Standardize all features such that they have \n",
    "    mean 0 and variance 1.\n",
    "    \n",
    "    If setmean, set all missing features to the mean of the feature\n",
    "    and add another column of 1's where it is missing and 0 where\n",
    "    it is not missing, to track the influence of the missing data.\n",
    "    \"\"\"\n",
    "    for j in range(features.shape[1]):\n",
    "        # all missing features\n",
    "        missing = features[:,j] == -1\n",
    "        # Ignore missing data for calculation of mean and variance\n",
    "        featcol = features[:,j][np.invert(missing)]\n",
    "        mean = np.mean(featcol)\n",
    "        std = np.std(featcol)\n",
    "        # Standardize the column\n",
    "        features[:,j] -= mean\n",
    "        features[:,j] /= std\n",
    "        if setmean:\n",
    "            # Put missing on zero, which is the mean of the feature\n",
    "            features[:,j][missing] = 0\n",
    "            # add another column\n",
    "            features = np.append(features,(missing^1)[:,np.newaxis],axis=1)\n",
    "        else:\n",
    "            # Put missing back to -1\n",
    "            features[:,j][missing] = -1\n",
    "            \n",
    "    return features\n",
    "\n",
    "def set_missing_to(features, value):\n",
    "    \"\"\"\n",
    "    Set all missing features to value\n",
    "    \"\"\"\n",
    "    missing = features == -1\n",
    "    features[missing] = value\n",
    "\n",
    "    return features\n",
    "\n",
    "def check_missing_data(features, labels):\n",
    "    missing = features == -1\n",
    "    # sum across rows to see how many features are missing\n",
    "    nummiss = np.sum(missing,axis=0)\n",
    "    print (\"Number of missing values per column\")\n",
    "    print (nummiss)\n",
    "    # decide to drop last three columns\n",
    "    features = features[:,:-3]\n",
    "    \n",
    "    # For the rest of the columns, check how many entries have all features\n",
    "    missing = features == -1\n",
    "    \n",
    "    # Mask array that is true where data is not missing\n",
    "    mask = np.sum(missing,axis=1) == 0\n",
    "    # The amount of rows without missing values\n",
    "    nomiss = np.sum(mask)\n",
    "    print (f\"Amount of datapoints that have all {features.shape[1]} features\")\n",
    "    print (nomiss)\n",
    "    \n",
    "    # Decide to use only these\n",
    "    features = features[mask]\n",
    "    labels = labels[mask]\n",
    "    \n",
    "    return features, labels\n",
    "    \n",
    "def split_even(features, labels):\n",
    "    \"\"\"\n",
    "    Make sure we have 50/50 long(1) vs short(0)\n",
    "    \n",
    "    Since the initial ratio is more like 3.5:1\n",
    "    \"\"\"\n",
    "    where1 = (labels == 1)[:,0]\n",
    "    features1 = features[where1]\n",
    "    labels1 = labels[where1]\n",
    "    \n",
    "    features0 = features[np.invert(where1)]\n",
    "    labels0 = labels[np.invert(where1)]\n",
    "    # Cut number of ones \n",
    "    features1 = features1[:len(features0)]\n",
    "    labels1 = labels1[:len(features0)]\n",
    "    \n",
    "    features2 = np.append(features1,features0,axis=0)\n",
    "    labels2 = np.append(labels1,labels0,axis=0)\n",
    "    \n",
    "    return features2, labels2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data (235, 6)\n",
      "(235, 12)\n"
     ]
    }
   ],
   "source": [
    "# Use only all except first 2 columns, those contain GRB and some index\n",
    "# The columns indicate\n",
    "# redshift, T90, log(M*/Msun), SFR, log(Z/Zsun), SSFR, AV\n",
    "data = np.loadtxt('./GRBs.txt', comments='#', usecols=(2,3,4,5,6,7,8))\n",
    "\n",
    "# Labels are based on T90 values\n",
    "T90 = data[:,1] \n",
    "labels = make_labels(T90) # shape (235,1)\n",
    "\n",
    "# Features are all things that are not T90\n",
    "features = np.copy(data[:,[0,2,3,4,5,6]]) # shape (235,6)\n",
    "\n",
    "print (\"Shape of the data\", features.shape)\n",
    "\n",
    "# First check missing values\n",
    "# features, labels = check_missing_data(features, labels)\n",
    "\n",
    "# features, labels = split_even(features, labels)\n",
    "# features, labels = check_missing_data(features, labels)\n",
    "\n",
    "# Only use first two columns\n",
    "features = features[:,:3]\n",
    "\n",
    "# Append all squared features, track missing values\n",
    "missing = features == -1\n",
    "sqfeatures = features**2.\n",
    "sqfeatures[missing] = -1\n",
    "features = np.append(features,sqfeatures,axis=1)  \n",
    "\n",
    "setmean = True\n",
    "# Then standardize the data, dealing with the missing values\n",
    "features = standardize(features,setmean)\n",
    "\n",
    "# # Append all cubed features, track missing values\n",
    "# missing = features[:,:2] == -1\n",
    "# sqfeatures = features[:,:2]**3.\n",
    "# sqfeatures[missing] = -1\n",
    "# # Standardize\n",
    "# sqfeatures = standardize(sqfeatures)\n",
    "# features = np.append(features,sqfeatures,axis=1)  \n",
    "\n",
    "print (features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last three columns have too many missing values to be valuable, as less than 20\\% of the data is available. So we disregard these columns. Then, from the output of the python script we see that there are 77 entries which have an entry in the first 3 columns, so we will use these as the examples to train on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use only all except first 2 columns, those contain GRB and some index\n",
    "# # The columns indicate\n",
    "# # redshift, T90, log(M*/Msun), SFR, log(Z/Zsun), SSFR, AV\n",
    "# data = np.loadtxt('./GRBs.txt', comments='#', usecols=(2,3,4,5,6,7,8))\n",
    "\n",
    "# # Labels are based on T90 values\n",
    "# T90 = data[:,1] \n",
    "# labels = make_labels(T90) # shape (235,1)\n",
    "\n",
    "# # Features are all things that are not T90\n",
    "# features = np.copy(data[:,[0,2,3,4,5,6]]) # shape (235,6)\n",
    "\n",
    "# corrmatrix = np.corrcoef(features,rowvar=False)\n",
    "# plt.imshow(corrmatrix)\n",
    "# print(corrmatrix)\n",
    "# print (\"Corr matrix makes no sense with missing values\")\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# setmean = True\n",
    "\n",
    "# # First standardize the data, ignoring the missing values\n",
    "# features = standardize(features, setmean=setmean)\n",
    "\n",
    "# # Only use first two columns\n",
    "# features = features[:,:2]\n",
    "\n",
    "# # Append all squared features, track missing values\n",
    "# missing = features == -1\n",
    "# sqfeatures = features**2.\n",
    "# sqfeatures[missing] = -1\n",
    "# # Standardize square features too\n",
    "# sqfeatures = standardize(sqfeatures, setmean=setmean)\n",
    "# features = np.append(features,sqfeatures,axis=1)  \n",
    "\n",
    "\n",
    "# print (features.shape)\n",
    "\n",
    "# # append mixes\n",
    "# # for i in range(0,6):\n",
    "# #     for j in range(0,i+1):\n",
    "# #         if i != j:\n",
    "# #             features = np.append(features,(features[:,i]*features[:,j])[:,np.newaxis],axis=1)  \n",
    "\n",
    "\n",
    "\n",
    "# flabels = ['Redshift', 'logM', 'SFR', 'logZ', 'SSFR', 'AV']\n",
    "\n",
    "# if setmean:\n",
    "#     missing = 0\n",
    "# else:\n",
    "#     missing = -1\n",
    "# # Print amount of missing features per column\n",
    "# for col in range(features.shape[1]//2):\n",
    "#     print (f'column {flabels[col]}, missing {np.sum(features[:,col]==missing)}')\n",
    "\n",
    "    \n",
    "# # Set missing to zero\n",
    "# # print (\"Setting missing to zero\")\n",
    "# # features = set_missing_to(features,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test set\n",
    "split = len(features)#//2\n",
    "indices = np.arange(0,len(features))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "features = features[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "train = features[:split]\n",
    "test = features[split:]\n",
    "\n",
    "features = train\n",
    "testlabels = labels[split:]\n",
    "labels = labels[:split]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69314718 0.6905451  0.68798895 0.68547788 0.68301106 0.68058769\n",
      " 0.67820696 0.67586809 0.67357031 0.67131285]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount predict Long 226.0\n",
      "Amount predict Short 9.0\n",
      "Amount Long:  182.0\n",
      "Amount Short:  53.0\n",
      "Amount incorrect: 50.0\n",
      "Accuracy 0.7872340425531915\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize weights and biases\n",
    "w = np.zeros((features.shape[1],1))\n",
    "b = 0\n",
    "\n",
    "numit = 10000\n",
    "loss = np.zeros(numit)\n",
    "alpha = 0.01\n",
    "for i in range(numit):\n",
    "    w, b, loss[i] = gradient_descent(w, features, b, labels, alpha, True)\n",
    "\n",
    "\n",
    "print (loss[:10])\n",
    "plt.plot(loss)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()\n",
    "\n",
    "# Final prediction\n",
    "yhat = sigmoid(np.dot(features,w)+b)\n",
    "# Decision boundary at 0.5\n",
    "yhat[yhat > 0.5] = 1\n",
    "yhat[yhat < 0.5] = 0\n",
    "print (\"Amount predict Long\", np.sum(yhat))\n",
    "print (\"Amount predict Short\", len(yhat)-np.sum(yhat))\n",
    "\n",
    "print (\"Amount Long: \", np.sum(labels))\n",
    "print (\"Amount Short: \", len(labels)-np.sum(labels))\n",
    "\n",
    "print ('Amount incorrect:', np.sum(np.abs(yhat-labels)))\n",
    "print ('Accuracy', 1 - np.sum(np.abs(yhat-labels))/len(labels))\n",
    "\n",
    "plt.hist(yhat.flatten(),label='Predictions',alpha=0.5)\n",
    "plt.hist(labels.flatten(),label='Actual values',alpha=0.5)\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel('Class label')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "\n",
    "if len(test) > 0:\n",
    "    print (\"Test set:\")\n",
    "    # Final prediction on test set\n",
    "    yhat = sigmoid(np.dot(test,w)+b)\n",
    "    # Decision boundary at 0.5\n",
    "    yhat[yhat > 0.5] = 1\n",
    "    yhat[yhat < 0.5] = 0\n",
    "    print (\"Amount predict Long\", np.sum(yhat))\n",
    "    print (\"Amount predict Short\", len(yhat)-np.sum(yhat))\n",
    "\n",
    "    print (\"Amount Long: \", np.sum(testlabels))\n",
    "    print (\"Amount Short: \", len(testlabels)-np.sum(testlabels))\n",
    "\n",
    "    print ('Amount incorrect:', np.sum(np.abs(yhat-testlabels)))\n",
    "    print ('Accuracy', 1 - np.sum(np.abs(yhat-testlabels))/len(testlabels))\n",
    "\n",
    "# print (np.where(np.abs(yhat-train_y_small))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (900,6) and (12,1) not aligned: 6 (dim 1) != 12 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-540-2c2a278edd58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0myhatp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mft1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (900,6) and (12,1) not aligned: 6 (dim 1) != 12 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Final prediction on whole 2D space\n",
    "all_features = np.zeros((30*30,2))\n",
    "count = 0\n",
    "for z in np.linspace(-1,3.8,30):\n",
    "    for logm in np.linspace(-2,2,30):\n",
    "        all_features[count] = [z,logm]\n",
    "        count +=1\n",
    "\n",
    "# Append first two squared.\n",
    "all_features = np.append(all_features,(all_features[:,0]**2)[:,np.newaxis],axis=1)  \n",
    "all_features = np.append(all_features,(all_features[:,1]**2)[:,np.newaxis],axis=1)  \n",
    "       \n",
    "# Append first two third.\n",
    "all_features = np.append(all_features,(all_features[:,0]**3)[:,np.newaxis],axis=1)  \n",
    "all_features = np.append(all_features,(all_features[:,1]**3)[:,np.newaxis],axis=1)  \n",
    "        \n",
    "    \n",
    "yhat = sigmoid(np.dot(features,w)+b)\n",
    "yhatp = sigmoid(np.dot(all_features,w)+b)\n",
    "\n",
    "ft1 = 0\n",
    "ft2 = 1\n",
    "# yhatp = yhatp > 0.5\n",
    "plt.scatter(all_features[:,ft1],all_features[:,ft2],c=yhatp[:,0]\n",
    "            ,vmin=0,vmax=1)\n",
    "plt.xlabel(flabels[ft1])\n",
    "plt.ylabel(flabels[ft2])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "yhat_predict = yhat>0.5\n",
    "ft1 = 0\n",
    "ft2 = 1\n",
    "plt.title(\"Predicted\")\n",
    "plt.scatter(features[:,ft1],features[:,ft2],c=yhat_predict[:,0])\n",
    "plt.xlabel(flabels[ft1])\n",
    "plt.ylabel(flabels[ft2])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "ft1 = 0\n",
    "ft2 = 1\n",
    "plt.title(\"Actual\")\n",
    "plt.scatter(features[:,ft1],features[:,ft2],c=labels[:,0])\n",
    "plt.xlabel(flabels[ft1])\n",
    "plt.ylabel(flabels[ft2])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check prediction on entire dataset\n",
    "data = np.loadtxt('./GRBs.txt', comments='#', usecols=(2,3,4,5,6,7,8))\n",
    "\n",
    "# Labels are based on T90 values\n",
    "T90 = data[:,1] \n",
    "labels = make_labels(T90) # shape (235,1)\n",
    "\n",
    "# Features are all things that are not T90\n",
    "features = np.copy(data[:,[0,2,3,4,5,6]]) # shape (235,6)\n",
    "\n",
    "print (\"Shape of the data\", features.shape)\n",
    "\n",
    "# Remove missing data\n",
    "features, labels = check_missing_data(features, labels)\n",
    "\n",
    "\n",
    "# Then standardize the data, ignoring the missing values\n",
    "features = standardize(features,setmean)\n",
    "\n",
    "# Only use first two columns\n",
    "features = features[:,:2]\n",
    "\n",
    "# Append all squared features, track missing values\n",
    "missing = features == -1\n",
    "sqfeatures = features**2.\n",
    "sqfeatures[missing] = -1\n",
    "# Standardize square features too\n",
    "sqfeatures = standardize(sqfeatures, setmean)\n",
    "features = np.append(features,sqfeatures,axis=1)  \n",
    "\n",
    "\n",
    "# Final prediction\n",
    "yhat = sigmoid(np.dot(features,w)+b)\n",
    "# Decision boundary at 0.5\n",
    "yhat[yhat > 0.5] = 1\n",
    "yhat[yhat < 0.5] = 0\n",
    "print (\"Amount predict Long\", np.sum(yhat))\n",
    "print (\"Amount predict Short\", len(yhat)-np.sum(yhat))\n",
    "\n",
    "print (\"Amount Long: \", np.sum(labels))\n",
    "print (\"Amount Short: \", len(labels)-np.sum(labels))\n",
    "\n",
    "print ('Amount incorrect:', np.sum(np.abs(yhat-labels)))\n",
    "print ('Accuracy', 1 - np.sum(np.abs(yhat-labels))/len(labels))\n",
    "\n",
    "plt.hist(yhat.flatten(),label='Predictions',alpha=0.5)\n",
    "plt.hist(labels.flatten(),label='Actual values',alpha=0.5)\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel('Class label')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Investigate data\n",
    "# plt.scatter(features[:,0],labels[:,0])\n",
    "# plt.xlabel('Redshift')\n",
    "# plt.ylabel('Class')\n",
    "# plt.show()\n",
    "\n",
    "data = np.loadtxt('./GRBs.txt', comments='#', usecols=(2,3,4,5,6,7,8))\n",
    "\n",
    "# Labels are based on T90 values\n",
    "T90 = data[:,1] \n",
    "labels = make_labels(T90) # shape (235,1)\n",
    "\n",
    "# Features are all things that are not T90\n",
    "features = np.copy(data[:,[0,2,3,4,5,6]]) # shape (235,6)\n",
    "\n",
    "print (\"Shape of the data\", features.shape)\n",
    "\n",
    "# First check missing values\n",
    "features, labels = check_missing_data(features, labels)\n",
    "\n",
    "\n",
    "# Then standardize the data, ignoring the missing values\n",
    "features = standardize(features)\n",
    "\n",
    "for i in range(0,features.shape[1]):\n",
    "    for j in range(0,i+1):\n",
    "        if i != j:\n",
    "            keep = np.bitwise_and(features[:,i] != 0, features[:,j] != 0)\n",
    "            fti = features[:,i][keep]\n",
    "            ftj = features[:,j][keep]\n",
    "#             plt.scatter(features[:,i],features[:,j],c=labels[:,0])\n",
    "\n",
    "            plt.title(f\"Num points {len(fti)}\")\n",
    "            plt.scatter(fti,ftj,c=labels[keep,0])\n",
    "            plt.xlabel(flabels[i])\n",
    "            plt.ylabel(flabels[j])\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# ft1 = 0\n",
    "# ft2 = 1\n",
    "# plt.scatter(features[:,ft1],features[:,ft2],c=labels[:,0])\n",
    "# plt.xlabel(flabels[ft1])\n",
    "# plt.ylabel(flabels[ft2])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# ft1 = 1\n",
    "# ft2 = 2\n",
    "# plt.scatter(features[:,ft1],features[:,ft2],c=labels[:,0])\n",
    "# plt.xlabel(flabels[ft1])\n",
    "# plt.ylabel(flabels[ft2])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# ft1 = 2\n",
    "# ft2 = 3\n",
    "# plt.scatter(features[:,ft1],features[:,ft2],c=labels[:,0])\n",
    "# plt.xlabel(flabels[ft1])\n",
    "# plt.ylabel(flabels[ft2])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# ft1 = 3\n",
    "# ft2 = 4\n",
    "# plt.scatter(features[:,ft1],features[:,ft2],c=labels[:,0])\n",
    "# plt.xlabel(flabels[ft1])\n",
    "# plt.ylabel(flabels[ft2])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# ft1 = 4\n",
    "# ft2 = 5\n",
    "# plt.scatter(features[:,ft1],features[:,ft2],c=labels[:,0])\n",
    "# plt.xlabel(flabels[ft1])\n",
    "# plt.ylabel(flabels[ft2])\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From inspecting the 2D projected plots, no clear regions can be found where the bursts are short as opposed to long. Therefore, the logistic regression algorithm does not perform very good. This is worsened by the fact that for all features except redshift, most of the values are missing. Combining features only makes sense if both features are not missing so effectively we only have very little features to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
